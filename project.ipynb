{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# droitGPT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM: Qwen-1_8B-Chat-Int4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "MAX_NEW_TOKENS = 8192\n",
    "\"\"\"\n",
    "Source: \n",
    "- context length: https://huggingface.co/Qwen/Qwen-1_8B-Chat-Int4\n",
    "\"\"\"\n",
    "MODEL_ID = \"Qwen/Qwen-1_8B-Chat-Int4\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID,device_map=\"auto\",trust_remote_code=True)\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=MAX_NEW_TOKENS)\n",
    "hf = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance - English\n",
    "Answer is good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model performance - French\n",
    "Answer is good enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Réponse: Réfléchissons étape par étape.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | hf\n",
    "\n",
    "question = \"Qu’est-ce que l’électroencéphalographie ?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test LLM with specific context\n",
    "Good performance so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "template = \"\"\"\n",
    "Vous êtes un assistant spécialisé en codes juridiques français.\n",
    "\n",
    "Utilisez les informations suivantes pour répondre à la question:\n",
    "<context>\n",
    "{context}\n",
    "<context>\n",
    "\n",
    "Question: {input}\n",
    "\n",
    "Réponse: En utilisant le contexte, répondre à la question.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "document_chain = create_stuff_documents_chain(hf, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "specific_context = \"\"\"Le Peuple français proclame solennellement son attachement aux Droits de l'Homme et aux principes de la souveraineté nationale tels qu'ils ont été définis par la Déclaration de 1789, confirmée et complétée par le préambule de la Constitution de 1946, ainsi qu'aux droits et devoirs définis dans la Charte de l'environnement de 2004.\"\"\" \n",
    "\n",
    "response = document_chain.invoke({\n",
    "    \"input\": \"Quels sont les éléments auxquels le Peuple français proclame solennellement son attachement dans ce texte ?\",\n",
    "    \"context\": [Document(page_content=specific_context)]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Transformers\n",
    "- Il faut trouver un modèle Sentence Transformers gratuit (donc pas de OpenAI Embeddings ni Ollama Embeddings)\n",
    "- Ce modèle doit être pre-entrainé pour la comparaison semantique\n",
    "- Ce modèle doit comprendre le français\n",
    "\n",
    "Source https://www.sbert.net/docs/pretrained_models.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model_id = 'sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2'\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus\n",
    "On va se limiter a 3 codes juridiques"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "data_folder = \"data\"\n",
    "relevant_files = [\"travail.md\", \"education.md\", \"electoral.md\"]\n",
    "\n",
    "clean_data_folder_name = \"clean_data\"\n",
    "\n",
    "if not os.path.exists(clean_data_folder_name):\n",
    "        os.makedirs(clean_data_folder_name)\n",
    "\n",
    "for file in os.listdir(data_folder):\n",
    "    if file in relevant_files:\n",
    "        file_path = data_folder + \"/\" + file \n",
    "        clean_file_path = clean_data_folder_name + \"/clean_\" + file\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "\n",
    "            # Transform textdata with re here\n",
    "            pattern1 = re.compile(r'---.*?---', re.DOTALL) # remove title and date \n",
    "            text = re.sub(pattern1, '', text)\n",
    "            \n",
    "            pattern2 = re.compile(r'#+.*\\n') # remove Markdown titles\n",
    "            text = re.sub(pattern2, '', text)\n",
    "\n",
    "            pattern2 = re.compile(r'\\*\\*.*\\*\\*') # remove Article titles\n",
    "            text = re.sub(pattern2, '', text)\n",
    "\n",
    "            pattern3 = re.compile(r'<div.*</div>') # remove html content (simple approach, usually tables)\n",
    "            text = re.sub(pattern3, '', text)\n",
    "\n",
    "            pattern4 = re.compile(r'([:;])\\n+') # form paragraphs\n",
    "            text = re.sub(pattern4,lambda x: x.group(1) + ' ', text)\n",
    "\n",
    "            with open(clean_file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 0\n",
    "\n",
    "data_folder = \"clean_data\"\n",
    "documents = []\n",
    "for file in os.listdir(data_folder):\n",
    "    filename = os.fsdecode(data_folder + \"/\" + file)\n",
    "    loader = TextLoader(filename)\n",
    "    documents += loader.load()\n",
    "\n",
    "docs = []\n",
    "for doc in documents:\n",
    "    texts = re.split('\\n+', doc.page_content)\n",
    "    texts = [text for text in texts if text]\n",
    "    for text in texts:\n",
    "        docs.append(Document(page_content = text, metadata=doc.metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))\n",
    "print()\n",
    "print(docs[0])\n",
    "print()\n",
    "print(docs[100])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vector = FAISS.from_documents(docs, embeddings)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying the Database\n",
    "On voit que les docs récuperés de la base de données sont un peu similaires au requête (modèle Embeddings n'est pas très grand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_context(docs_and_scores):\n",
    "    for i, (doc, score) in enumerate(docs_and_scores):\n",
    "        print(f\"Top {i+1}\")\n",
    "        print(doc.page_content)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"L'éducation des jeunes sourds\"\n",
    "docs_and_scores = vector.similarity_search_with_score(query)\n",
    "print_context(docs_and_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Contrat de travail à durée déterminée\"\n",
    "docs_and_scores = vector.similarity_search_with_score(query)\n",
    "print_context(docs_and_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Le mandat de conseiller départemental est incompatible\"\n",
    "docs_and_scores = vector.similarity_search_with_score(query)\n",
    "print_context(docs_and_scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Vector Database as context depending on the input/question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(response):\n",
    "    print(\"Answer:\")\n",
    "    print(response[\"answer\"])\n",
    "    print()\n",
    "    print(\"Context:\")\n",
    "    contexts = response[\"context\"]\n",
    "    for i, doc in enumerate(contexts):\n",
    "        print(f\"Top {i+1}\")\n",
    "        print(doc.page_content)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "\n",
    "retriever = vector.as_retriever()\n",
    "retrieval_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Code Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Est-ce que l'education est la première priorité nationale en France?\"\n",
    "response = retrieval_chain.invoke({\"input\": question})\n",
    "print_response(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Code Electoral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Qu'est ce que tu connais sur le code electoral français?\"\n",
    "response = retrieval_chain.invoke({\"input\": question})\n",
    "print_response(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test - Code Travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Est-ce qu'une organisation syndicale de salariés peut agir devant une juridiction civile?\"\n",
    "response = retrieval_chain.invoke({\"input\": question})\n",
    "print_response(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0f8cf80e483949ce106b92424a3ebbfefd398ce3c643f9d8bf14e7a2613db07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
